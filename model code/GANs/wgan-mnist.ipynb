{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.utils import save_image\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entraînement sur : cuda\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# 1. CONFIGURATION\n",
        "# ==========================================\n",
        "class Config:\n",
        "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    \n",
        "    # WGAN-GP MNIST\n",
        "    LR = 1e-4\n",
        "    BATCH_SIZE = 64\n",
        "    IMAGE_SIZE = 28\n",
        "    CHANNELS = 1\n",
        "    Z_DIM = 100\n",
        "    NUM_EPOCHS = 50\n",
        "    FEATURES_DIM = 64\n",
        "    CRITIC_ITERATIONS = 5\n",
        "    LAMBDA_GP = 10\n",
        "    \n",
        "    # Chemins\n",
        "    # Dataset : ../../dataset (Torchvision ajoutera /MNIST automatiquement)\n",
        "    DATA_ROOT = os.path.join(\"..\", \"..\", \"dataset\") \n",
        "    IMG_DIR = \"samples\"\n",
        "    CKPT_NAME = \"wgan_mnist_ckpt.pth\"\n",
        "    SAVE_EVERY = 5\n",
        "\n",
        "conf = Config()\n",
        "print(f\"Entraînement sur : {conf.DEVICE}\")\n",
        "\n",
        "os.makedirs(conf.IMG_DIR, exist_ok=True)\n",
        "ckpt_path_full = conf.CKPT_NAME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# 2. ARCHITECTURES (MNIST 28x28)\n",
        "# ==========================================\n",
        "class Critic(nn.Module):\n",
        "    def __init__(self, channels_img, features_d):\n",
        "        super(Critic, self).__init__()\n",
        "        self.critic = nn.Sequential(\n",
        "            nn.Conv2d(channels_img, features_d, 4, 2, 1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(features_d, features_d * 2, 4, 2, 1),\n",
        "            nn.InstanceNorm2d(features_d * 2, affine=True),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(features_d * 2, features_d * 4, 4, 2, 1),\n",
        "            nn.InstanceNorm2d(features_d * 4, affine=True),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(features_d * 4, 1, 3, 1, 0),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.critic(x)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim, channels_img, features_g):\n",
        "        super(Generator, self).__init__()\n",
        "        self.gen = nn.Sequential(\n",
        "            nn.ConvTranspose2d(z_dim, features_g * 4, 7, 1, 0),\n",
        "            nn.BatchNorm2d(features_g * 4),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(features_g * 4, features_g * 2, 4, 2, 1),\n",
        "            nn.BatchNorm2d(features_g * 2),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(features_g * 2, channels_img, 4, 2, 1),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.gen(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# 3. GRADIENT PENALTY\n",
        "# ==========================================\n",
        "def gradient_penalty(critic, real, fake, device):\n",
        "    BATCH_SIZE, C, H, W = real.shape\n",
        "    epsilon = torch.rand((BATCH_SIZE, 1, 1, 1)).repeat(1, C, H, W).to(device)\n",
        "    interpolated = real * epsilon + fake * (1 - epsilon)\n",
        "    interpolated.requires_grad_(True)\n",
        "    mixed_scores = critic(interpolated)\n",
        "    gradient = torch.autograd.grad(\n",
        "        inputs=interpolated,\n",
        "        outputs=mixed_scores,\n",
        "        grad_outputs=torch.ones_like(mixed_scores),\n",
        "        create_graph=True,\n",
        "        retain_graph=True,\n",
        "    )[0]\n",
        "    gradient = gradient.view(gradient.shape[0], -1)\n",
        "    gradient_norm = gradient.norm(2, dim=1)\n",
        "    return torch.mean((gradient_norm - 1) ** 2)\n",
        "\n",
        "# ==========================================\n",
        "# 4. INITIALISATION\n",
        "# ==========================================\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(conf.IMAGE_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5], [0.5]),\n",
        "])\n",
        "\n",
        "dataset = torchvision.datasets.MNIST(root=conf.DATA_ROOT, train=True, transform=transform, download=True)\n",
        "loader = DataLoader(dataset, batch_size=conf.BATCH_SIZE, shuffle=True)\n",
        "\n",
        "gen = Generator(conf.Z_DIM, conf.CHANNELS, conf.FEATURES_DIM).to(conf.DEVICE)\n",
        "critic = Critic(conf.CHANNELS, conf.FEATURES_DIM).to(conf.DEVICE)\n",
        "opt_gen = optim.Adam(gen.parameters(), lr=conf.LR, betas=(0.0, 0.9))\n",
        "opt_critic = optim.Adam(critic.parameters(), lr=conf.LR, betas=(0.0, 0.9))\n",
        "fixed_noise = torch.randn(64, conf.Z_DIM, 1, 1).to(conf.DEVICE)\n",
        "\n",
        "start_epoch = 0\n",
        "if os.path.exists(ckpt_path_full):\n",
        "    print(f\"Chargement du checkpoint : {ckpt_path_full}\")\n",
        "    ckpt = torch.load(ckpt_path_full, map_location=conf.DEVICE)\n",
        "    gen.load_state_dict(ckpt[\"gen_state\"])\n",
        "    critic.load_state_dict(ckpt[\"critic_state\"])\n",
        "    opt_gen.load_state_dict(ckpt[\"opt_gen_state\"])\n",
        "    opt_critic.load_state_dict(ckpt[\"opt_critic_state\"])\n",
        "    start_epoch = ckpt[\"epoch\"] + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Début de l'entraînement MNIST...\n",
            "--> Epoch 5\n",
            "    [TIMING] Temps de Forward pour 64 images : 0.00250 sec\n",
            "    [TIMING] Temps moyen par image : 0.000039 sec\n",
            "--> Epoch 10\n",
            "    [TIMING] Temps de Forward pour 64 images : 0.00102 sec\n",
            "    [TIMING] Temps moyen par image : 0.000016 sec\n",
            "--> Epoch 15\n",
            "    [TIMING] Temps de Forward pour 64 images : 0.00098 sec\n",
            "    [TIMING] Temps moyen par image : 0.000015 sec\n",
            "--> Epoch 20\n",
            "    [TIMING] Temps de Forward pour 64 images : 0.00707 sec\n",
            "    [TIMING] Temps moyen par image : 0.000110 sec\n",
            "--> Epoch 25\n",
            "    [TIMING] Temps de Forward pour 64 images : 0.00289 sec\n",
            "    [TIMING] Temps moyen par image : 0.000045 sec\n",
            "--> Epoch 30\n",
            "    [TIMING] Temps de Forward pour 64 images : 0.00000 sec\n",
            "    [TIMING] Temps moyen par image : 0.000000 sec\n",
            "--> Epoch 35\n",
            "    [TIMING] Temps de Forward pour 64 images : 0.00199 sec\n",
            "    [TIMING] Temps moyen par image : 0.000031 sec\n",
            "--> Epoch 40\n",
            "    [TIMING] Temps de Forward pour 64 images : 0.00033 sec\n",
            "    [TIMING] Temps moyen par image : 0.000005 sec\n",
            "--> Epoch 45\n",
            "    [TIMING] Temps de Forward pour 64 images : 0.00000 sec\n",
            "    [TIMING] Temps moyen par image : 0.000000 sec\n",
            "--> Epoch 50\n",
            "    [TIMING] Temps de Forward pour 64 images : 0.00062 sec\n",
            "    [TIMING] Temps moyen par image : 0.000010 sec\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# 5. BOUCLE D'ENTRAÎNEMENT + TIMING\n",
        "# ==========================================\n",
        "print(\"Début de l'entraînement MNIST...\")\n",
        "\n",
        "for epoch in range(start_epoch, conf.NUM_EPOCHS):\n",
        "    gen.train()\n",
        "    critic.train()\n",
        "    \n",
        "    for batch_idx, (real, _) in enumerate(loader):\n",
        "        real = real.to(conf.DEVICE)\n",
        "        cur_batch_size = real.shape[0]\n",
        "\n",
        "        # Train Critic\n",
        "        for _ in range(conf.CRITIC_ITERATIONS):\n",
        "            noise = torch.randn(cur_batch_size, conf.Z_DIM, 1, 1).to(conf.DEVICE)\n",
        "            fake = gen(noise)\n",
        "            critic_real = critic(real).reshape(-1)\n",
        "            critic_fake = critic(fake).reshape(-1)\n",
        "            gp = gradient_penalty(critic, real, fake, conf.DEVICE)\n",
        "            loss_critic = -(torch.mean(critic_real) - torch.mean(critic_fake)) + conf.LAMBDA_GP * gp\n",
        "            critic.zero_grad()\n",
        "            loss_critic.backward(retain_graph=True)\n",
        "            opt_critic.step()\n",
        "\n",
        "        # Train Generator\n",
        "        gen_fake = critic(fake).reshape(-1)\n",
        "        loss_gen = -torch.mean(gen_fake)\n",
        "        gen.zero_grad()\n",
        "        loss_gen.backward()\n",
        "        opt_gen.step()\n",
        "\n",
        "    # --- Sauvegarde & Mesure du temps de Forward ---\n",
        "    if (epoch + 1) % conf.SAVE_EVERY == 0 or (epoch + 1) == conf.NUM_EPOCHS:\n",
        "        print(f\"--> Epoch {epoch+1}\")\n",
        "        \n",
        "        # Sauvegarde PTH\n",
        "        torch.save({\n",
        "            \"epoch\": epoch,\n",
        "            \"gen_state\": gen.state_dict(),\n",
        "            \"critic_state\": critic.state_dict(),\n",
        "            \"opt_gen_state\": opt_gen.state_dict(),\n",
        "            \"opt_critic_state\": opt_critic.state_dict(),\n",
        "        }, ckpt_path_full)\n",
        "        \n",
        "        # Génération & Timing\n",
        "        gen.eval()\n",
        "        \n",
        "        # Synchronisation GPU pour une mesure précise du temps (si CUDA)\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.synchronize()\n",
        "            \n",
        "        start_time = time.time()  # <--- DÉBUT CHRONO\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            fake_img = gen(fixed_noise) # FORWARD PASS\n",
        "            \n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.synchronize()\n",
        "            \n",
        "        end_time = time.time()    # <--- FIN CHRONO\n",
        "        forward_duration = end_time - start_time\n",
        "        \n",
        "        print(f\"    [TIMING] Temps de Forward pour {conf.BATCH_SIZE} images : {forward_duration:.5f} sec\")\n",
        "        print(f\"    [TIMING] Temps moyen par image : {forward_duration/conf.BATCH_SIZE:.6f} sec\")\n",
        "\n",
        "        # Sauvegarde Image\n",
        "        fake_img = (fake_img * 0.5) + 0.5\n",
        "        save_path = os.path.join(conf.IMG_DIR, f\"epoch_{epoch+1}.png\")\n",
        "        save_image(fake_img, save_path, nrow=8)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
