{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb46e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532ea180",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                                     (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "\n",
    "trainset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "loader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db3c5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "class VPSDE:\n",
    "    def __init__(self, beta_min=0.1, beta_max=20.0, T=1.0):\n",
    "        self.beta_min = beta_min\n",
    "        self.beta_max = beta_max\n",
    "        self.T = T\n",
    "\n",
    "    def beta(self, t):\n",
    "        # t in [0,1], shape [B]\n",
    "        return self.beta_min + t * (self.beta_max - self.beta_min)\n",
    "\n",
    "    def int_beta(self, t):\n",
    "        # ∫0^t beta(s) ds for linear beta\n",
    "        return self.beta_min * t + 0.5 * (self.beta_max - self.beta_min) * t**2\n",
    "\n",
    "    def alpha(self, t):\n",
    "        # alpha(t) = exp(-1/2 ∫ beta)\n",
    "        return torch.exp(-0.5 * self.int_beta(t))\n",
    "\n",
    "    def sigma(self, t):\n",
    "        # sigma(t) = sqrt(1 - alpha(t)^2)\n",
    "        a = self.alpha(t)\n",
    "        return torch.sqrt(1.0 - a*a).clamp(min=1e-5)\n",
    "\n",
    "    def diffusion(self, t):\n",
    "        # g(t) = sqrt(beta(t))\n",
    "        return torch.sqrt(self.beta(t)).clamp(min=1e-5)\n",
    "\n",
    "    def drift(self, x, t):\n",
    "        # f(x,t) = -1/2 beta(t) x\n",
    "        b = self.beta(t).view(-1, 1, 1, 1)\n",
    "        return -0.5 * b * x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffa3d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TimeEmbedding(nn.Module):\n",
    "    def __init__(self, dim=32):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.lin = nn.Linear(dim, dim)\n",
    "\n",
    "    def forward(self, t):\n",
    "        half_dim = self.dim // 2\n",
    "        emb = torch.exp(\n",
    "            torch.arange(half_dim, device=t.device) * -(torch.log(torch.tensor(10000.0, device=t.device)) / half_dim)\n",
    "        )\n",
    "        emb = t[:, None] * emb[None, :]\n",
    "        emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=-1)\n",
    "        return self.lin(emb)  # [B, dim]\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, groups=32):\n",
    "        super().__init__()\n",
    "        # groups must divide out_ch. For 128,256,512,1024 channels, 32 works.\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.GroupNorm(groups, out_ch),\n",
    "            nn.SiLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.GroupNorm(groups, out_ch),\n",
    "            nn.SiLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361558ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetScoreCIFAR3Level(nn.Module):\n",
    "    def __init__(self, time_dim=32, base_channels=128, img_channels=3):\n",
    "        super().__init__()\n",
    "        self.time_mlp = TimeEmbedding(dim=time_dim)\n",
    "        in_ch = img_channels + time_dim  # 3 + time_dim\n",
    "\n",
    "        C = base_channels\n",
    "\n",
    "        # -------- Encoder --------\n",
    "        self.down1 = ConvBlock(in_ch, C)        # 32x32\n",
    "        self.pool1 = nn.MaxPool2d(2)            # 32->16\n",
    "\n",
    "        self.down2 = ConvBlock(C, 2*C)          # 16x16\n",
    "        self.pool2 = nn.MaxPool2d(2)            # 16->8\n",
    "\n",
    "        self.down3 = ConvBlock(2*C, 4*C)        # 8x8\n",
    "        self.pool3 = nn.MaxPool2d(2)            # 8->4\n",
    "\n",
    "        # -------- Bottleneck --------\n",
    "        self.bottleneck = ConvBlock(4*C, 8*C)   # 4x4\n",
    "\n",
    "        # -------- Decoder --------\n",
    "        self.up3 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode=\"nearest\"),\n",
    "            nn.Conv2d(8*C, 4*C, 3, padding=1),\n",
    "        )\n",
    "\n",
    "        self.dec3 = ConvBlock(8*C, 4*C)          # concat(4C + 4C)=8C -> 4C\n",
    "\n",
    "        self.up2 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode=\"nearest\"),     # 8 -> 16\n",
    "            nn.Conv2d(4*C, 2*C, kernel_size=3, padding=1),\n",
    "        )\n",
    "        self.dec2 = ConvBlock(4*C, 2*C)          # concat(2C + 2C)=4C -> 2C\n",
    "\n",
    "        self.up1 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode=\"nearest\"),     # 16 -> 32\n",
    "            nn.Conv2d(2*C, C, kernel_size=3, padding=1),\n",
    "        )\n",
    "        self.dec1 = ConvBlock(2*C, C)            # concat(C + C)=2C -> C\n",
    "\n",
    "        # score output has same channels as x: 3\n",
    "        self.out_conv = nn.Conv2d(C, img_channels, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        # time embedding to spatial map\n",
    "        emb = self.time_mlp(t)                   # [B, time_dim]\n",
    "        emb = emb[:, :, None, None]              # [B, time_dim, 1, 1]\n",
    "        emb = emb.expand(-1, -1, x.size(2), x.size(3))  # [B, time_dim, H, W]\n",
    "\n",
    "        x_in = torch.cat([x, emb], dim=1)        # [B, 3+time_dim, 32, 32]\n",
    "\n",
    "        # Encoder\n",
    "        d1 = self.down1(x_in)                    # [B, C, 32, 32]\n",
    "        p1 = self.pool1(d1)                      # [B, C, 16, 16]\n",
    "\n",
    "        d2 = self.down2(p1)                      # [B, 2C, 16, 16]\n",
    "        p2 = self.pool2(d2)                      # [B, 2C, 8, 8]\n",
    "\n",
    "        d3 = self.down3(p2)                      # [B, 4C, 8, 8]\n",
    "        p3 = self.pool3(d3)                      # [B, 4C, 4, 4]\n",
    "\n",
    "        # Bottleneck\n",
    "        b = self.bottleneck(p3)                  # [B, 8C, 4, 4]\n",
    "\n",
    "        # Decoder\n",
    "        u3 = self.up3(b)                         # [B, 4C, 8, 8]\n",
    "        u3 = torch.cat([u3, d3], dim=1)          # [B, 8C, 8, 8]\n",
    "        u3 = self.dec3(u3)                       # [B, 4C, 8, 8]\n",
    "\n",
    "        u2 = self.up2(u3)                        # [B, 2C, 16, 16]\n",
    "        u2 = torch.cat([u2, d2], dim=1)          # [B, 4C, 16, 16]\n",
    "        u2 = self.dec2(u2)                       # [B, 2C, 16, 16]\n",
    "\n",
    "        u1 = self.up1(u2)                        # [B, C, 32, 32]\n",
    "        u1 = torch.cat([u1, d1], dim=1)          # [B, 2C, 32, 32]\n",
    "        u1 = self.dec1(u1)                       # [B, C, 32, 32]\n",
    "\n",
    "        return self.out_conv(u1)                 # [B, 3, 32, 32]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbc69ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def vp_sample_xt(x0, t, sde):\n",
    "    \"\"\"\n",
    "    x0: [B,3,32,32], t: [B]\n",
    "    returns xt, eps where xt = alpha x0 + sigma eps\n",
    "    \"\"\"\n",
    "    a = sde.alpha(t).view(-1, 1, 1, 1)\n",
    "    s = sde.sigma(t).view(-1, 1, 1, 1)\n",
    "    eps = torch.randn_like(x0)\n",
    "    xt = a * x0 + s * eps\n",
    "    return xt, eps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887cc85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "ckpt_path = \"vp_cifar_ckpt.pth\"\n",
    "\n",
    "# ---- hyperparams ----\n",
    "time_dim = 32\n",
    "base_channels = 128\n",
    "img_channels = 3\n",
    "\n",
    "beta_min = 0.1\n",
    "beta_max = 20.0\n",
    "T = 1.0\n",
    "\n",
    "lr = 3e-5\n",
    "weight_decay = 1e-4\n",
    "\n",
    "ema_decay = 0.999\n",
    "t_min = 1e-4\n",
    "\n",
    "num_epochs_total = 150      # total epochs you want to reach\n",
    "save_every = 10\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def update_ema(ema_model, model, decay):\n",
    "    for p_ema, p in zip(ema_model.parameters(), model.parameters()):\n",
    "        p_ema.data.mul_(decay).add_(p.data, alpha=1 - decay)\n",
    "\n",
    "\n",
    "# ---- build models ----\n",
    "model = UNetScoreCIFAR3Level(time_dim=time_dim, base_channels=base_channels, img_channels=img_channels).to(device)\n",
    "ema_model = UNetScoreCIFAR3Level(time_dim=time_dim, base_channels=base_channels, img_channels=img_channels).to(device)\n",
    "\n",
    "# ---- build SDE ----\n",
    "sde = VPSDE(beta_min=beta_min, beta_max=beta_max, T=T)\n",
    "\n",
    "# ---- optimizer ----\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "# ---- resume if possible ----\n",
    "start_epoch = 0\n",
    "if os.path.exists(ckpt_path):\n",
    "    ckpt = torch.load(ckpt_path, map_location=device)\n",
    "\n",
    "    # Safety: only resume if architecture matches; otherwise it will error here.\n",
    "    model.load_state_dict(ckpt[\"model_state\"])\n",
    "    ema_model.load_state_dict(ckpt[\"ema_state\"])\n",
    "\n",
    "    if \"optimizer_state\" in ckpt:\n",
    "        optimizer.load_state_dict(ckpt[\"optimizer_state\"])\n",
    "\n",
    "    # Restore schedule params if present (avoids mismatch)\n",
    "    if \"beta_min\" in ckpt and \"beta_max\" in ckpt and \"T\" in ckpt:\n",
    "        sde = VPSDE(beta_min=float(ckpt[\"beta_min\"]), beta_max=float(ckpt[\"beta_max\"]), T=float(ckpt[\"T\"]))\n",
    "\n",
    "    start_epoch = int(ckpt.get(\"epoch\", -1)) + 1\n",
    "\n",
    "    # IMPORTANT: optimizer state restores old LR; overwrite with desired LR\n",
    "    for g in optimizer.param_groups:\n",
    "        g[\"lr\"] = lr\n",
    "        g[\"weight_decay\"] = weight_decay\n",
    "\n",
    "    print(f\"Resuming from {ckpt_path} at epoch {start_epoch} (lr={optimizer.param_groups[0]['lr']})\")\n",
    "\n",
    "else:\n",
    "    # start fresh\n",
    "    ema_model.load_state_dict(model.state_dict())\n",
    "    print(f\"No checkpoint found at {ckpt_path}. Starting fresh at epoch 0 (lr={lr}).\")\n",
    "\n",
    "\n",
    "# ---- training ----\n",
    "end_epoch = num_epochs_total\n",
    "\n",
    "for epoch in range(start_epoch, end_epoch):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    n_batches = 0\n",
    "\n",
    "    for x0, _ in loader:\n",
    "        x0 = x0.to(device)\n",
    "\n",
    "        # t ~ Uniform(t_min, 1)\n",
    "        t = t_min + (1.0 - t_min) * torch.rand(x0.size(0), device=device)\n",
    "\n",
    "        xt, eps = vp_sample_xt(x0, t, sde)\n",
    "        eps_pred = model(xt, t)\n",
    "\n",
    "        loss = F.mse_loss(eps_pred, eps)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        update_ema(ema_model, model, ema_decay)\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        n_batches += 1\n",
    "\n",
    "    mean_loss = epoch_loss / max(n_batches, 1)\n",
    "    print(f\"Epoch {epoch+1}/{end_epoch}: mean loss = {mean_loss:.4f}\")\n",
    "\n",
    "    # ---- checkpoint ----\n",
    "    if (epoch + 1) % save_every == 0 or (epoch + 1) == end_epoch:\n",
    "        torch.save(\n",
    "            {\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state\": model.state_dict(),\n",
    "                \"ema_state\": ema_model.state_dict(),\n",
    "                \"optimizer_state\": optimizer.state_dict(),\n",
    "                \"beta_min\": sde.beta_min,\n",
    "                \"beta_max\": sde.beta_max,\n",
    "                \"T\": sde.T,\n",
    "                \"time_dim\": time_dim,\n",
    "                \"base_channels\": base_channels,\n",
    "                \"img_channels\": img_channels,\n",
    "                \"t_min\": t_min,\n",
    "            },\n",
    "            ckpt_path,\n",
    "        )\n",
    "        print(f\"Checkpoint saved at epoch {epoch+1} → {ckpt_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b7e077",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def sample_prob_flow_ode(model, sde, num_steps=2000, batch_size=16, device=\"cuda\", t_min=1e-4):\n",
    "    model.eval()\n",
    "    t_grid = torch.linspace(1.0, t_min, num_steps, device=device)\n",
    "\n",
    "    x = torch.randn(batch_size, 3, 32, 32, device=device)\n",
    "\n",
    "    for i in range(num_steps - 1):\n",
    "        t_cur = t_grid[i]\n",
    "        t_next = t_grid[i+1]\n",
    "        dt = t_next - t_cur  # negative\n",
    "\n",
    "        t_batch = torch.full((batch_size,), t_cur, device=device)\n",
    "\n",
    "        beta = sde.beta(t_batch).view(batch_size, 1, 1, 1)\n",
    "        sigma = sde.sigma(t_batch).view(batch_size, 1, 1, 1)\n",
    "\n",
    "        eps_pred = model(x, t_batch)\n",
    "        score = -eps_pred / sigma\n",
    "\n",
    "        f = -0.5 * beta * x\n",
    "        drift = f - 0.5 * beta * score\n",
    "\n",
    "        x = x + drift * dt\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c4a9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "def show_cifar_grid(x, nrow=4, title=\"Samples\"):\n",
    "    x = x.detach().cpu()\n",
    "    x = (x.clamp(-1, 1) + 1) / 2.0  # -> [0,1]\n",
    "    B = x.size(0)\n",
    "    ncol = math.ceil(B / nrow)\n",
    "\n",
    "    plt.figure(figsize=(ncol*2, nrow*2))\n",
    "    for i in range(B):\n",
    "        plt.subplot(nrow, ncol, i+1)\n",
    "        img = x[i].permute(1, 2, 0).numpy()\n",
    "        plt.imshow(img)\n",
    "        plt.axis(\"off\")\n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7395cbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(ckpt_path, map_location=device)\n",
    "model.load_state_dict(ckpt[\"model_state\"])\n",
    "ema_model.load_state_dict(ckpt[\"ema_state\"])\n",
    "samples = sample_prob_flow_ode(ema_model, sde, num_steps=4000, batch_size=16, device=device, t_min=1e-4)\n",
    "show_cifar_grid(samples, nrow=4, title=\"CIFAR-10 samples (VP + ODE, EMA)\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
