{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d450a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTEBOOK TO RUN THE FINAL DIFFUSION MODEL WITH ATTENTION AT ALL LEVELS. YOU SHOULD RUN THIS ON A GPU OR ANYWHERE WITH CUDA \n",
    "# COMPATIBILITY AS GENERATION CAN BE VERY LONG ON A CPU. THE WEIGHTS ARE DOWNLOADED FROM MY GOOGLE DRIVE (Antoine). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f732c038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /opt/python/lib/python3.13/site-packages (5.2.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/python/lib/python3.13/site-packages (from gdown) (4.14.3)\n",
      "Requirement already satisfied: filelock in /opt/python/lib/python3.13/site-packages (from gdown) (3.20.1)\n",
      "Requirement already satisfied: requests[socks] in /opt/python/lib/python3.13/site-packages (from gdown) (2.32.5)\n",
      "Requirement already satisfied: tqdm in /opt/python/lib/python3.13/site-packages (from gdown) (4.67.1)\n",
      "Requirement already satisfied: soupsieve>=1.6.1 in /opt/python/lib/python3.13/site-packages (from beautifulsoup4->gdown) (2.8.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /opt/python/lib/python3.13/site-packages (from beautifulsoup4->gdown) (4.15.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/python/lib/python3.13/site-packages (from requests[socks]->gdown) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/python/lib/python3.13/site-packages (from requests[socks]->gdown) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/python/lib/python3.13/site-packages (from requests[socks]->gdown) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/python/lib/python3.13/site-packages (from requests[socks]->gdown) (2025.11.12)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/python/lib/python3.13/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e768a76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /opt/python/lib/python3.13/site-packages (3.10.8)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/python/lib/python3.13/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/python/lib/python3.13/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/python/lib/python3.13/site-packages (from matplotlib) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/python/lib/python3.13/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/python/lib/python3.13/site-packages (from matplotlib) (2.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/python/lib/python3.13/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /opt/python/lib/python3.13/site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /opt/python/lib/python3.13/site-packages (from matplotlib) (3.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/python/lib/python3.13/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/python/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0854cb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368f1918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMA weights already downloaded.\n"
     ]
    }
   ],
   "source": [
    "import gdown\n",
    "import os\n",
    "\n",
    "file_id = \"1JKHdVVaw2ySOuuPJCcL94tnyHyavV4Xj\"\n",
    "out_path = \"ema_weights_final_model.pth\"\n",
    "\n",
    "if not os.path.exists(out_path):\n",
    "    gdown.download(\n",
    "        f\"https://drive.google.com/uc?id={file_id}\",\n",
    "        out_path,\n",
    "        quiet=False,\n",
    "    )\n",
    "else:\n",
    "    print(\"EMA weights already downloaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213cc2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(torch.cuda.is_available()) # Make sure it prints true !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2420e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -------------------------\n",
    "# Model (matches your checkpoint keys)\n",
    "# -------------------------\n",
    "class TimeEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    Sinusoidal timestep embedding -> small MLP.\n",
    "    Produces a vector of size time_dim.\n",
    "    \"\"\"\n",
    "    def __init__(self, dim=128, hidden_mult=4):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        hidden = dim * hidden_mult\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(dim, hidden),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden, dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        # t: [B] float in [0, 1]\n",
    "        half_dim = self.dim // 2\n",
    "        freqs = torch.exp(\n",
    "            torch.arange(half_dim, device=t.device, dtype=t.dtype)\n",
    "            * -(torch.log(torch.tensor(10000.0, device=t.device, dtype=t.dtype)) / half_dim)\n",
    "        )\n",
    "        args = t[:, None] * freqs[None, :]  # [B, half_dim]\n",
    "        emb = torch.cat([torch.sin(args), torch.cos(args)], dim=-1)  # [B, dim] if dim even\n",
    "        if emb.shape[1] != self.dim:\n",
    "            # if dim is odd, pad\n",
    "            emb = F.pad(emb, (0, self.dim - emb.shape[1]))\n",
    "        return self.mlp(emb)\n",
    "\n",
    "class ResBlockFiLM(nn.Module):\n",
    "    \"\"\"\n",
    "    ResBlock with FiLM conditioning from an embedding vector (time+label).\n",
    "    Conditioning is applied as scale+shift after GroupNorm:\n",
    "        h = GN(h) * (1 + scale) + shift\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch, out_ch, emb_dim, groups=32, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.in_ch = in_ch\n",
    "        self.out_ch = out_ch\n",
    "\n",
    "        self.norm1 = nn.GroupNorm(groups, in_ch)\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1)\n",
    "\n",
    "        self.norm2 = nn.GroupNorm(groups, out_ch)\n",
    "        self.dropout = nn.Dropout(dropout) if dropout > 0 else nn.Identity()\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1)\n",
    "\n",
    "        # project embedding -> (scale, shift)\n",
    "        self.emb_proj = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(emb_dim, 2 * out_ch),\n",
    "        )\n",
    "\n",
    "        self.skip = nn.Identity() if in_ch == out_ch else nn.Conv2d(in_ch, out_ch, 1)\n",
    "\n",
    "    def forward(self, x, emb):\n",
    "        # x: [B,C,H,W], emb: [B, emb_dim]\n",
    "        h = self.norm1(x)\n",
    "        h = F.silu(h)\n",
    "        h = self.conv1(h)\n",
    "\n",
    "        h = self.norm2(h)\n",
    "        scale_shift = self.emb_proj(emb)  # [B, 2*out_ch]\n",
    "        scale, shift = torch.chunk(scale_shift, 2, dim=1)\n",
    "        scale = scale[:, :, None, None]\n",
    "        shift = shift[:, :, None, None]\n",
    "        h = h * (1.0 + scale) + shift\n",
    "\n",
    "        h = F.silu(h)\n",
    "        h = self.dropout(h)\n",
    "        h = self.conv2(h)\n",
    "\n",
    "        return h + self.skip(x)\n",
    "\n",
    "class SelfAttention2d(nn.Module):\n",
    "    def __init__(self, channels, num_heads=4, gn_groups=32):\n",
    "        super().__init__()\n",
    "        assert channels % num_heads == 0\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = channels // num_heads\n",
    "        self.scale = self.head_dim ** -0.5\n",
    "\n",
    "        self.norm = nn.GroupNorm(gn_groups, channels)\n",
    "        self.qkv = nn.Conv2d(channels, 3 * channels, kernel_size=1, bias=False)\n",
    "        self.proj = nn.Conv2d(channels, channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        h = self.norm(x)\n",
    "        qkv = self.qkv(h)  # [B,3C,H,W]\n",
    "        q, k, v = qkv.chunk(3, dim=1)\n",
    "\n",
    "        N = H * W\n",
    "        q = q.view(B, self.num_heads, self.head_dim, N).permute(0, 1, 3, 2)  # [B,h,N,d]\n",
    "        k = k.view(B, self.num_heads, self.head_dim, N)                      # [B,h,d,N]\n",
    "        v = v.view(B, self.num_heads, self.head_dim, N).permute(0, 1, 3, 2)  # [B,h,N,d]\n",
    "\n",
    "        attn = (q @ k) * self.scale\n",
    "        attn = attn.softmax(dim=-1)\n",
    "\n",
    "        out = attn @ v\n",
    "        out = out.permute(0, 1, 3, 2).contiguous().view(B, C, H, W)\n",
    "        out = self.proj(out)\n",
    "        return x + out\n",
    "\n",
    "class UNetCIFAR3Level_Attn_CFG(nn.Module):\n",
    "    \"\"\"\n",
    "    ε-prediction U-Net with attention at 32x32, 16x16, 8x8 and 4x4,\n",
    "    plus classifier-free guidance conditioning via null label = num_classes.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        time_dim=32,\n",
    "        base_channels=128,\n",
    "        img_channels=3,\n",
    "        num_classes=10,\n",
    "        attn_heads=4,\n",
    "        dropout=0.0,\n",
    "        gn_groups=32,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.time_dim = time_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.null_label = num_classes\n",
    "\n",
    "        self.time_mlp = TimeEmbedding(dim=time_dim)\n",
    "        self.label_emb = nn.Embedding(num_classes + 1, time_dim)\n",
    "\n",
    "        C = base_channels\n",
    "        emb_dim = time_dim\n",
    "\n",
    "        # Stem\n",
    "        self.in_conv = nn.Conv2d(img_channels, C, 3, padding=1)\n",
    "\n",
    "        # Encoder\n",
    "        self.down1 = ResBlockFiLM(C, C, emb_dim, groups=gn_groups, dropout=dropout)\n",
    "        self.attn32 = SelfAttention2d(C, num_heads=attn_heads, gn_groups=gn_groups)\n",
    "        self.pool1 = nn.MaxPool2d(2)  # 32 -> 16\n",
    "\n",
    "        self.down2 = ResBlockFiLM(C, 2 * C, emb_dim, groups=gn_groups, dropout=dropout)\n",
    "        self.attn16 = SelfAttention2d(2 * C, num_heads=attn_heads, gn_groups=gn_groups)\n",
    "        self.pool2 = nn.MaxPool2d(2)  # 16 -> 8\n",
    "\n",
    "        self.down3 = ResBlockFiLM(2 * C, 4 * C, emb_dim, groups=gn_groups, dropout=dropout)\n",
    "        self.attn8 = SelfAttention2d(4 * C, num_heads=attn_heads, gn_groups=gn_groups)\n",
    "        self.pool3 = nn.MaxPool2d(2)  # 8 -> 4\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = ResBlockFiLM(4 * C, 8 * C, emb_dim, groups=gn_groups, dropout=dropout)\n",
    "        self.attn4 = SelfAttention2d(8 * C, num_heads=attn_heads, gn_groups=gn_groups)\n",
    "\n",
    "        # Decoder\n",
    "        self.up3 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode=\"nearest\"),\n",
    "            nn.Conv2d(8 * C, 4 * C, 3, padding=1),\n",
    "        )\n",
    "        self.dec3 = ResBlockFiLM(8 * C, 4 * C, emb_dim, groups=gn_groups, dropout=dropout)\n",
    "        self.dec3_attn = SelfAttention2d(4 * C, num_heads=attn_heads, gn_groups=gn_groups)\n",
    "\n",
    "        self.up2 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode=\"nearest\"),\n",
    "            nn.Conv2d(4 * C, 2 * C, 3, padding=1),\n",
    "        )\n",
    "        self.dec2 = ResBlockFiLM(4 * C, 2 * C, emb_dim, groups=gn_groups, dropout=dropout)\n",
    "        self.dec2_attn16 = SelfAttention2d(2 * C, num_heads=attn_heads, gn_groups=gn_groups)\n",
    "\n",
    "        self.up1 = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode=\"nearest\"),\n",
    "            nn.Conv2d(2 * C, C, 3, padding=1),\n",
    "        )\n",
    "        self.dec1 = ResBlockFiLM(2 * C, C, emb_dim, groups=gn_groups, dropout=dropout)\n",
    "        self.dec1_attn32 = SelfAttention2d(C, num_heads=attn_heads, gn_groups=gn_groups)\n",
    "\n",
    "        self.out_norm = nn.GroupNorm(gn_groups, C)\n",
    "        self.out_conv = nn.Conv2d(C, img_channels, 3, padding=1)\n",
    "\n",
    "    def forward(self, x, t, y=None):\n",
    "        B = x.shape[0]\n",
    "        temb = self.time_mlp(t)\n",
    "\n",
    "        if y is None:\n",
    "            y = torch.full((B,), self.null_label, device=x.device, dtype=torch.long)\n",
    "        yemb = self.label_emb(y)\n",
    "\n",
    "        emb = temb + yemb\n",
    "\n",
    "        h0 = self.in_conv(x)\n",
    "\n",
    "        d1 = self.down1(h0, emb)\n",
    "        d1 = self.attn32(d1)\n",
    "        p1 = self.pool1(d1)\n",
    "\n",
    "        d2 = self.down2(p1, emb)\n",
    "        d2 = self.attn16(d2)\n",
    "        p2 = self.pool2(d2)\n",
    "\n",
    "        d3 = self.down3(p2, emb)\n",
    "        d3 = self.attn8(d3)\n",
    "        p3 = self.pool3(d3)\n",
    "\n",
    "        b = self.bottleneck(p3, emb)\n",
    "        b = self.attn4(b)\n",
    "\n",
    "        u3 = self.up3(b)\n",
    "        u3 = torch.cat([u3, d3], dim=1)\n",
    "        u3 = self.dec3(u3, emb)\n",
    "        u3 = self.dec3_attn(u3)\n",
    "\n",
    "        u2 = self.up2(u3)\n",
    "        u2 = torch.cat([u2, d2], dim=1)\n",
    "        u2 = self.dec2(u2, emb)\n",
    "        u2 = self.dec2_attn16(u2)\n",
    "\n",
    "        u1 = self.up1(u2)\n",
    "        u1 = torch.cat([u1, d1], dim=1)\n",
    "        u1 = self.dec1(u1, emb)\n",
    "        u1 = self.dec1_attn32(u1)\n",
    "\n",
    "        out = self.out_norm(u1)\n",
    "        out = F.silu(out)\n",
    "        out = self.out_conv(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# VPSDE + sampler\n",
    "# -------------------------\n",
    "class VPSDE:\n",
    "    def __init__(self, beta_min=0.1, beta_max=20.0, T=1.0):\n",
    "        self.beta_min = float(beta_min)\n",
    "        self.beta_max = float(beta_max)\n",
    "        self.T = float(T)\n",
    "\n",
    "    def beta(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        return self.beta_min + t * (self.beta_max - self.beta_min)\n",
    "\n",
    "    def int_beta(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        return self.beta_min * t + 0.5 * (self.beta_max - self.beta_min) * t**2\n",
    "\n",
    "    def alpha(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.exp(-0.5 * self.int_beta(t))\n",
    "\n",
    "    def sigma(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        a = self.alpha(t)\n",
    "        return torch.sqrt((1.0 - a * a).clamp(min=1e-12))\n",
    "\n",
    "    def drift(self, x: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        b = self.beta(t).view(-1, 1, 1, 1)\n",
    "        return -0.5 * b * x\n",
    "\n",
    "@torch.no_grad()\n",
    "def sample_prob_flow_heun_eps_cfg(\n",
    "    model: nn.Module,\n",
    "    sde: VPSDE,\n",
    "    y: torch.Tensor,                 # [B] labels 0..9\n",
    "    guidance_w: float = 4.0,\n",
    "    num_steps: int = 200,\n",
    "    t_min: float = 1e-4,\n",
    "    img_size: int = 32,\n",
    "    img_channels: int = 3,\n",
    "    clamp_x: bool = True,\n",
    "    clamp_val: float = 2.0,\n",
    "    time_power: float = 2.0,\n",
    "    device: str = \"cuda\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Probability-flow ODE with Heun integration using eps-prediction + CFG.\n",
    "\n",
    "    score(x,t) = -eps(x,t) / sigma(t)\n",
    "    dx/dt = f(x,t) - 0.5 * g(t)^2 * score(x,t)\n",
    "         = drift(x,t) - 0.5*beta(t) * (-eps/sigma)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    B = y.shape[0]\n",
    "    y = y.to(device).long()\n",
    "\n",
    "    # time grid: more steps near small t\n",
    "    u = torch.linspace(0.0, 1.0, num_steps, device=device)\n",
    "    t_grid = t_min + (1.0 - t_min) * (u ** time_power)\n",
    "    t_grid = torch.flip(t_grid, dims=[0])  # 1 -> t_min\n",
    "\n",
    "    x = torch.randn(B, img_channels, img_size, img_size, device=device)\n",
    "\n",
    "    def ode_drift(x: torch.Tensor, t_scalar: float) -> torch.Tensor:\n",
    "        t = torch.full((B,), float(t_scalar), device=device, dtype=x.dtype)\n",
    "\n",
    "        beta  = sde.beta(t).view(B, 1, 1, 1)\n",
    "        sigma = sde.sigma(t).view(B, 1, 1, 1).clamp_min(1e-12)\n",
    "\n",
    "        # unconditional (null label) via y=None\n",
    "        eps_u = model(x, t, y=None)\n",
    "        eps_c = model(x, t, y=y)\n",
    "\n",
    "        eps = eps_u + guidance_w * (eps_c - eps_u)\n",
    "\n",
    "        drift = sde.drift(x, t) - 0.5 * beta * (-eps / sigma)\n",
    "        return drift\n",
    "\n",
    "    for i in range(len(t_grid) - 1):\n",
    "        t0 = t_grid[i].item()\n",
    "        t1 = t_grid[i + 1].item()\n",
    "        dt = t1 - t0  # negative\n",
    "\n",
    "        k1 = ode_drift(x, t0)\n",
    "        x_pred = x + dt * k1\n",
    "        k2 = ode_drift(x_pred, t1)\n",
    "\n",
    "        x = x + 0.5 * dt * (k1 + k2)\n",
    "\n",
    "        if clamp_x:\n",
    "            x = x.clamp(-clamp_val, clamp_val)\n",
    "\n",
    "    return x\n",
    "\n",
    "@torch.no_grad()\n",
    "def sample_one_per_class(model, sde, guidance_w=4.0, num_steps=200, t_min=1e-4, device=\"cuda\"):\n",
    "    labels = torch.arange(10, device=device)\n",
    "    x = sample_prob_flow_heun_eps_cfg(\n",
    "        model=model,\n",
    "        sde=sde,\n",
    "        y=labels,\n",
    "        guidance_w=guidance_w,\n",
    "        num_steps=num_steps,\n",
    "        t_min=t_min,\n",
    "        device=device,\n",
    "    )\n",
    "    return x, labels\n",
    "\n",
    "CIFAR10_NAMES = [\n",
    "    \"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\",\n",
    "    \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"\n",
    "]\n",
    "\n",
    "def to_01(x):\n",
    "    \"\"\"Map from [-1,1] → [0,1].\"\"\"\n",
    "    return (x.clamp(-1, 1) + 1) * 0.5\n",
    "\n",
    "def show_class_row(samples, labels=None, title=\"One sample per class\"):\n",
    "    \"\"\"\n",
    "    samples: [B,3,32,32] in [-1,1]\n",
    "    labels:  [B] optional\n",
    "    \"\"\"\n",
    "    x = to_01(samples.detach().cpu())\n",
    "    B = x.size(0)\n",
    "\n",
    "    plt.figure(figsize=(2 * B, 2.5))\n",
    "    for i in range(B):\n",
    "        plt.subplot(1, B, i + 1)\n",
    "        img = x[i].permute(1, 2, 0).numpy()\n",
    "        plt.imshow(img)\n",
    "        plt.axis(\"off\")\n",
    "        if labels is not None:\n",
    "            lbl = int(labels[i])\n",
    "            plt.title(CIFAR10_NAMES[lbl], fontsize=9)\n",
    "\n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_grid(samples, nrow=4, title=\"Samples\"):\n",
    "    x = to_01(samples.detach().cpu())\n",
    "    B = x.size(0)\n",
    "    ncol = math.ceil(B / nrow)\n",
    "\n",
    "    plt.figure(figsize=(2 * ncol, 2 * nrow))\n",
    "    for i in range(B):\n",
    "        plt.subplot(nrow, ncol, i + 1)\n",
    "        img = x[i].permute(1, 2, 0).numpy()\n",
    "        plt.imshow(img)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# --- match training hyperparams ---\n",
    "num_classes = 10\n",
    "time_dim = 32\n",
    "base_channels = 128\n",
    "img_channels = 3\n",
    "attn_heads = 4\n",
    "beta_min = 0.1\n",
    "beta_max = 20.0\n",
    "T = 1.0\n",
    "\n",
    "ema_weights_path = \"ema_weights_final_model.pth\"\n",
    "\n",
    "# Build model + load EMA weights\n",
    "ema_model = UNetCIFAR3Level_Attn_CFG(\n",
    "    time_dim=time_dim,\n",
    "    base_channels=base_channels,\n",
    "    img_channels=img_channels,\n",
    "    num_classes=num_classes,\n",
    "    attn_heads=attn_heads,\n",
    ").to(device)\n",
    "\n",
    "ema_sd = torch.load(ema_weights_path, map_location=device)\n",
    "ema_model.load_state_dict(ema_sd, strict=True)\n",
    "ema_model.eval()\n",
    "\n",
    "# Build SDE\n",
    "sde = VPSDE(beta_min=beta_min, beta_max=beta_max, T=T)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57b81fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ema_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 249\u001b[39m\n\u001b[32m    245\u001b[39m T_MIN = \u001b[32m1e-4\u001b[39m\n\u001b[32m    246\u001b[39m TIME_POWER = \u001b[32m2.0\u001b[39m    \u001b[38;5;66;03m# keep same as notebook unless you intentionally change it\u001b[39;00m\n\u001b[32m    248\u001b[39m bench_final_b16 = run_sampling_benchmark(\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m     \u001b[43mema_model\u001b[49m, sde, sampler_prob_flow_heun_cfg_timed,\n\u001b[32m    250\u001b[39m     num_steps=NUM_STEPS,\n\u001b[32m    251\u001b[39m     batch_size=\u001b[32m16\u001b[39m,\n\u001b[32m    252\u001b[39m     device=device,\n\u001b[32m    253\u001b[39m     t_min=T_MIN,\n\u001b[32m    254\u001b[39m     guidance_w=GUIDANCE_W,\n\u001b[32m    255\u001b[39m     time_power=TIME_POWER,\n\u001b[32m    256\u001b[39m     num_classes=\u001b[32m10\u001b[39m,\n\u001b[32m    257\u001b[39m )\n\u001b[32m    258\u001b[39m pretty_print_summary(bench_final_b16, name=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFINAL model | Heun PF-ODE + CFG | steps=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mNUM_STEPS\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | w=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mGUIDANCE_W\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | batch=16\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    260\u001b[39m bench_final_b128 = run_sampling_benchmark(\n\u001b[32m    261\u001b[39m     ema_model, sde, sampler_prob_flow_heun_cfg_timed,\n\u001b[32m    262\u001b[39m     num_steps=NUM_STEPS,\n\u001b[32m   (...)\u001b[39m\u001b[32m    268\u001b[39m     num_classes=\u001b[32m10\u001b[39m,\n\u001b[32m    269\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'ema_model' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# ---------------------------\n",
    "# Utilities\n",
    "# ---------------------------\n",
    "def _sync_if_cuda(device):\n",
    "    if isinstance(device, str):\n",
    "        is_cuda = \"cuda\" in device\n",
    "    else:\n",
    "        is_cuda = (device.type == \"cuda\")\n",
    "    if is_cuda and torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "def _percentiles(xs, ps=(50, 95)):\n",
    "    xs = np.asarray(xs, dtype=np.float64)\n",
    "    return {f\"p{p}\": float(np.percentile(xs, p)) for p in ps}\n",
    "\n",
    "class TimedModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Wraps your model to:\n",
    "      - count NFEs (number of model forward calls)\n",
    "      - accumulate forward time using CUDA events\n",
    "    \"\"\"\n",
    "    def __init__(self, model: nn.Module, device=\"cuda\"):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.reset_stats()\n",
    "\n",
    "    def reset_stats(self):\n",
    "        self.nfe = 0\n",
    "        self.model_ms = 0.0\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, *args, **kwargs):\n",
    "        self.nfe += 1\n",
    "\n",
    "        if torch.cuda.is_available() and (\"cuda\" in str(self.device)):\n",
    "            start = torch.cuda.Event(enable_timing=True)\n",
    "            end = torch.cuda.Event(enable_timing=True)\n",
    "            start.record()\n",
    "            out = self.model(*args, **kwargs)\n",
    "            end.record()\n",
    "            torch.cuda.synchronize()\n",
    "            self.model_ms += start.elapsed_time(end)\n",
    "            return out\n",
    "        else:\n",
    "            t0 = time.perf_counter()\n",
    "            out = self.model(*args, **kwargs)\n",
    "            t1 = time.perf_counter()\n",
    "            self.model_ms += (t1 - t0) * 1000.0\n",
    "            return out\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Timed sampler wrapper for THIS notebook:\n",
    "# uses your existing: sample_prob_flow_heun_eps_cfg(model, sde, y, ...)\n",
    "# ---------------------------------------------------------------------\n",
    "@torch.no_grad()\n",
    "def sampler_prob_flow_heun_cfg_timed(\n",
    "    timed_model,\n",
    "    sde,\n",
    "    *,\n",
    "    batch_size: int,\n",
    "    num_steps: int,\n",
    "    guidance_w: float,\n",
    "    t_min: float,\n",
    "    device: str,\n",
    "    time_power: float = 2.0,\n",
    "    num_classes: int = 10,\n",
    "):\n",
    "    # Random labels 0..9 (same approach you used previously)\n",
    "    y = torch.randint(low=0, high=num_classes, size=(batch_size,), device=device)\n",
    "\n",
    "    # Call YOUR notebook's sampler function directly (important!)\n",
    "    x = sample_prob_flow_heun_eps_cfg(\n",
    "        model=timed_model,\n",
    "        sde=sde,\n",
    "        y=y,\n",
    "        guidance_w=guidance_w,\n",
    "        num_steps=num_steps,\n",
    "        t_min=t_min,\n",
    "        time_power=time_power,\n",
    "        device=device,\n",
    "        clamp_x=True,\n",
    "    )\n",
    "    return x\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Benchmark runner\n",
    "# ---------------------------\n",
    "def run_sampling_benchmark(\n",
    "    model: nn.Module,\n",
    "    sde,\n",
    "    sampler_fn,\n",
    "    *,\n",
    "    num_steps: int,\n",
    "    batch_size: int,\n",
    "    device=\"cuda\",\n",
    "    t_min=1e-4,\n",
    "    warmup_runs=2,\n",
    "    timed_runs=10,\n",
    "    reset_cuda_peak_mem=True,\n",
    "    **sampler_kwargs,\n",
    "):\n",
    "    timed_model = TimedModel(model, device=device).to(device)\n",
    "\n",
    "    # Warmup\n",
    "    for _ in range(warmup_runs):\n",
    "        timed_model.reset_stats()\n",
    "        _sync_if_cuda(device)\n",
    "        _ = sampler_fn(\n",
    "            timed_model, sde,\n",
    "            batch_size=batch_size,\n",
    "            num_steps=num_steps,\n",
    "            device=device,\n",
    "            t_min=t_min,\n",
    "            **sampler_kwargs\n",
    "        )\n",
    "        _sync_if_cuda(device)\n",
    "\n",
    "    per_img_total_ms = []\n",
    "    per_img_model_ms = []\n",
    "    per_img_overhead_ms = []\n",
    "\n",
    "    nfes_per_run = []\n",
    "    ms_per_forward_total = []\n",
    "    ms_per_forward_model = []\n",
    "    throughput_img_per_s = []\n",
    "\n",
    "    peak_alloc_mb = []\n",
    "    peak_reserved_mb = []\n",
    "\n",
    "    for _ in range(timed_runs):\n",
    "        timed_model.reset_stats()\n",
    "\n",
    "        if reset_cuda_peak_mem and torch.cuda.is_available() and (\"cuda\" in str(device)):\n",
    "            torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "        _sync_if_cuda(device)\n",
    "        t0 = time.perf_counter()\n",
    "        _ = sampler_fn(\n",
    "            timed_model, sde,\n",
    "            batch_size=batch_size,\n",
    "            num_steps=num_steps,\n",
    "            device=device,\n",
    "            t_min=t_min,\n",
    "            **sampler_kwargs\n",
    "        )\n",
    "        _sync_if_cuda(device)\n",
    "        t1 = time.perf_counter()\n",
    "\n",
    "        total_ms_batch = (t1 - t0) * 1000.0\n",
    "        model_ms_batch = float(timed_model.model_ms)\n",
    "        overhead_ms_batch = total_ms_batch - model_ms_batch\n",
    "\n",
    "        nfe_batch = int(timed_model.nfe)\n",
    "        nfes_per_run.append(nfe_batch)\n",
    "\n",
    "        total_ms_img = total_ms_batch / batch_size\n",
    "        model_ms_img = model_ms_batch / batch_size\n",
    "        overhead_ms_img = overhead_ms_batch / batch_size\n",
    "\n",
    "        per_img_total_ms.append(total_ms_img)\n",
    "        per_img_model_ms.append(model_ms_img)\n",
    "        per_img_overhead_ms.append(overhead_ms_img)\n",
    "\n",
    "        denom = max(nfe_batch, 1)\n",
    "        ms_per_forward_total.append(total_ms_batch / denom)\n",
    "        ms_per_forward_model.append(model_ms_batch / denom)\n",
    "\n",
    "        throughput_img_per_s.append(1000.0 / max(total_ms_img, 1e-12))\n",
    "\n",
    "        if torch.cuda.is_available() and (\"cuda\" in str(device)):\n",
    "            peak_alloc_mb.append(torch.cuda.max_memory_allocated() / (1024**2))\n",
    "            peak_reserved_mb.append(torch.cuda.max_memory_reserved() / (1024**2))\n",
    "\n",
    "    # NFE/sample: for diffusion, each sample gets all evaluations; NFE/sample == nfe_batch\n",
    "    nfe_per_sample = nfes_per_run\n",
    "    nfe_per_img_legacy = [n / batch_size for n in nfes_per_run]\n",
    "\n",
    "    summary = {\n",
    "        \"num_steps\": num_steps,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"t_min\": t_min,\n",
    "        \"timed_runs\": timed_runs,\n",
    "\n",
    "        \"nfe_per_sample_percentiles\": _percentiles(nfe_per_sample, ps=(50, 95)),\n",
    "        \"nfe_per_img_legacy_percentiles\": _percentiles(nfe_per_img_legacy, ps=(50,)),\n",
    "\n",
    "        \"total_ms_percentiles\": _percentiles(per_img_total_ms, ps=(50, 95)),\n",
    "        \"model_ms_percentiles\": _percentiles(per_img_model_ms, ps=(50, 95)),\n",
    "        \"overhead_ms_percentiles\": _percentiles(per_img_overhead_ms, ps=(50, 95)),\n",
    "\n",
    "        \"ms_per_forward_total_percentiles\": _percentiles(ms_per_forward_total, ps=(50, 95)),\n",
    "        \"ms_per_forward_model_percentiles\": _percentiles(ms_per_forward_model, ps=(50, 95)),\n",
    "\n",
    "        \"throughput_img_per_s_percentiles\": _percentiles(throughput_img_per_s, ps=(50, 95)),\n",
    "    }\n",
    "\n",
    "    if peak_alloc_mb:\n",
    "        summary[\"peak_alloc_mb_p50\"] = _percentiles(peak_alloc_mb, ps=(50,))[\"p50\"]\n",
    "        summary[\"peak_reserved_mb_p50\"] = _percentiles(peak_reserved_mb, ps=(50,))[\"p50\"]\n",
    "\n",
    "    return summary\n",
    "\n",
    "\n",
    "def pretty_print_summary(summary: dict, name=\"\"):\n",
    "    print(f\"\\n=== Benchmark: {name} ===\")\n",
    "    print(f\"steps={summary['num_steps']} | batch={summary['batch_size']} | timed_runs={summary['timed_runs']}\")\n",
    "    print(f\"NFE/sample p50: {summary['nfe_per_sample_percentiles']['p50']:.1f} | p95: {summary['nfe_per_sample_percentiles']['p95']:.1f}\")\n",
    "    print(f\"NFE/img (legacy: NFE/sample ÷ batch) p50: {summary['nfe_per_img_legacy_percentiles']['p50']:.3f}\")\n",
    "\n",
    "    print(f\"total ms/img p50: {summary['total_ms_percentiles']['p50']:.3f} | p95: {summary['total_ms_percentiles']['p95']:.3f}\")\n",
    "    print(f\"model ms/img p50: {summary['model_ms_percentiles']['p50']:.3f} | p95: {summary['model_ms_percentiles']['p95']:.3f}\")\n",
    "    print(f\"overhd ms/img p50: {summary['overhead_ms_percentiles']['p50']:.3f} | p95: {summary['overhead_ms_percentiles']['p95']:.3f}\")\n",
    "\n",
    "    print(\n",
    "        f\"ms/forward TOTAL p50: {summary['ms_per_forward_total_percentiles']['p50']:.6f} | \"\n",
    "        f\"p95: {summary['ms_per_forward_total_percentiles']['p95']:.6f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"ms/forward MODEL p50: {summary['ms_per_forward_model_percentiles']['p50']:.6f} | \"\n",
    "        f\"p95: {summary['ms_per_forward_model_percentiles']['p95']:.6f}\"\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"throughput img/s p50: {summary['throughput_img_per_s_percentiles']['p50']:.2f} | \"\n",
    "        f\"p95: {summary['throughput_img_per_s_percentiles']['p95']:.2f}\"\n",
    "    )\n",
    "\n",
    "    if \"peak_alloc_mb_p50\" in summary:\n",
    "        print(f\"peak alloc MB p50: {summary['peak_alloc_mb_p50']:.1f} | peak reserved MB p50: {summary['peak_reserved_mb_p50']:.1f}\")\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Run both batch sizes (16 + 128)\n",
    "# ---------------------------\n",
    "GUIDANCE_W = 4.0\n",
    "NUM_STEPS = 500     # as you requested\n",
    "T_MIN = 1e-4\n",
    "TIME_POWER = 2.0    # keep same as notebook unless you intentionally change it\n",
    "\n",
    "bench_final_b16 = run_sampling_benchmark(\n",
    "    ema_model, sde, sampler_prob_flow_heun_cfg_timed,\n",
    "    num_steps=NUM_STEPS,\n",
    "    batch_size=16,\n",
    "    device=device,\n",
    "    t_min=T_MIN,\n",
    "    guidance_w=GUIDANCE_W,\n",
    "    time_power=TIME_POWER,\n",
    "    num_classes=10,\n",
    ")\n",
    "pretty_print_summary(bench_final_b16, name=f\"FINAL model | Heun PF-ODE + CFG | steps={NUM_STEPS} | w={GUIDANCE_W} | batch=16\")\n",
    "\n",
    "bench_final_b128 = run_sampling_benchmark(\n",
    "    ema_model, sde, sampler_prob_flow_heun_cfg_timed,\n",
    "    num_steps=NUM_STEPS,\n",
    "    batch_size=128,\n",
    "    device=device,\n",
    "    t_min=T_MIN,\n",
    "    guidance_w=GUIDANCE_W,\n",
    "    time_power=TIME_POWER,\n",
    "    num_classes=10,\n",
    ")\n",
    "pretty_print_summary(bench_final_b128, name=f\"FINAL model | Heun PF-ODE + CFG | steps={NUM_STEPS} | w={GUIDANCE_W} | batch=128\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
