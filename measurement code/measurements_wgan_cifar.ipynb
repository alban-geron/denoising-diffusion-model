{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9954b1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import os\n",
    "import gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e59498c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargement de wgan_cifar_advanced_ckpt.pth...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1axjh_HshUWWEXoOLbf2L83WTtMKv0VkE\n",
      "From (redirected): https://drive.google.com/uc?id=1axjh_HshUWWEXoOLbf2L83WTtMKv0VkE&confirm=t&uuid=9c84ef28-40d8-4fab-8d81-5656ab7b408a\n",
      "To: /home/onyxia/work/denoising-diffusion-model/measurement code/wgan_cifar_advanced_ckpt.pth\n",
      "100%|██████████| 70.8M/70.8M [00:01<00:00, 60.6MB/s]\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 1. TÉLÉCHARGEMENT\n",
    "# ==========================================\n",
    "file_id = \"1axjh_HshUWWEXoOLbf2L83WTtMKv0VkE\"\n",
    "out_path = \"wgan_cifar_advanced_ckpt.pth\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if not os.path.exists(out_path):\n",
    "    print(f\"Téléchargement de {out_path}...\")\n",
    "    gdown.download(f\"https://drive.google.com/uc?id={file_id}\", out_path, quiet=False)\n",
    "else:\n",
    "    print(\"Fichier checkpoint déjà présent.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37f2fe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 2. ARCHITECTURE CORRIGÉE (Instance Norm)\n",
    "# ==========================================\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.query_conv = nn.Conv2d(in_dim, in_dim // 8, kernel_size=1)\n",
    "        self.key_conv = nn.Conv2d(in_dim, in_dim // 8, kernel_size=1)\n",
    "        self.value_conv = nn.Conv2d(in_dim, in_dim, kernel_size=1)\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, C, width, height = x.size()\n",
    "        proj_query = self.query_conv(x).view(batch_size, -1, width * height).permute(0, 2, 1)\n",
    "        proj_key = self.key_conv(x).view(batch_size, -1, width * height)\n",
    "        energy = torch.bmm(proj_query, proj_key)\n",
    "        attention = self.softmax(energy)\n",
    "        proj_value = self.value_conv(x).view(batch_size, -1, width * height)\n",
    "        out = torch.bmm(proj_value, attention.permute(0, 2, 1))\n",
    "        out = out.view(batch_size, C, width, height)\n",
    "        return self.gamma * out + x\n",
    "\n",
    "class GeneratorCorrected(nn.Module):\n",
    "    def __init__(self, z_dim, channels_img, features_g=128):\n",
    "        super(GeneratorCorrected, self).__init__()\n",
    "        \n",
    "        # Helper block: Upsample + Conv + INSTANCE NORM\n",
    "        def block(in_channels, out_channels, normalize=True):\n",
    "            layers = [\n",
    "                nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "                nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
    "            ]\n",
    "            if normalize:\n",
    "                # CORRECTION ICI : InstanceNorm2d au lieu de BatchNorm2d\n",
    "                # affine=True permet d'apprendre des poids (weight/bias) comme BatchNorm\n",
    "                # mais sans stocker running_mean/var\n",
    "                layers.append(nn.InstanceNorm2d(out_channels, affine=True))\n",
    "            layers.append(nn.ReLU())\n",
    "            return layers\n",
    "\n",
    "        self.initial = nn.Sequential(\n",
    "            nn.ConvTranspose2d(z_dim, features_g * 4, 4, 1, 0),\n",
    "            # CORRECTION ICI AUSSI\n",
    "            nn.InstanceNorm2d(features_g * 4, affine=True),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            *block(features_g * 4, features_g * 2),\n",
    "        )\n",
    "        \n",
    "        self.attn = SelfAttention(features_g * 2)\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            *block(features_g * 2, features_g),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.Conv2d(features_g, channels_img, 3, 1, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.initial(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.attn(out)\n",
    "        return self.layer2(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6c99666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement du checkpoint : wgan_cifar_advanced_ckpt.pth\n",
      ">> Poids EMA détectés (Meilleure qualité)\n",
      ">> Poids chargés avec SUCCÈS ! (Architecture InstanceNorm validée)\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 3. CHARGEMENT ET GÉNÉRATION\n",
    "# ==========================================\n",
    "Z_DIM = 100\n",
    "CHANNELS = 3\n",
    "FEATURES_DIM = 128\n",
    "\n",
    "# Instanciation du modèle corrigé\n",
    "model = GeneratorCorrected(Z_DIM, CHANNELS, features_g=FEATURES_DIM).to(device)\n",
    "\n",
    "print(f\"Chargement du checkpoint : {out_path}\")\n",
    "ckpt = torch.load(out_path, map_location=device)\n",
    "\n",
    "# Sélection du bon dictionnaire de poids\n",
    "if \"ema_state\" in ckpt:\n",
    "    state_dict = ckpt[\"ema_state\"]\n",
    "    print(\">> Poids EMA détectés (Meilleure qualité)\")\n",
    "elif \"gen_state\" in ckpt:\n",
    "    state_dict = ckpt[\"gen_state\"]\n",
    "    print(\">> Poids standards détectés\")\n",
    "else:\n",
    "    state_dict = ckpt\n",
    "\n",
    "# Chargement\n",
    "try:\n",
    "    model.load_state_dict(state_dict)\n",
    "    print(\">> Poids chargés avec SUCCÈS ! (Architecture InstanceNorm validée)\")\n",
    "except RuntimeError as e:\n",
    "    print(f\"\\nERREUR ENCORE PRÉSENTE : {e}\")\n",
    "    print(\"Essai de chargement avec strict=False (Risqué mais peut marcher)...\")\n",
    "    model.load_state_dict(state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9331d0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Benchmark: WGAN CIFAR | Generator | batch=16 ===\n",
      "batch=16 | timed_runs=10\n",
      "NFE/sample: 1\n",
      "total ms/img p50: 0.275251 | p95: 0.277356\n",
      "model ms/img p50: 0.269369 | p95: 0.270967\n",
      "overhd ms/img p50: 0.005852 | p95: 0.006702\n",
      "ms/forward (model) p50: 0.269369 | p95: 0.270967\n",
      "throughput img/s p50: 3633.06 | p95: 3649.90\n",
      "peak alloc MB p50: 113.6 | peak reserved MB p50: 508.0\n",
      "\n",
      "=== Benchmark: WGAN CIFAR | Generator | batch=128 ===\n",
      "batch=128 | timed_runs=10\n",
      "NFE/sample: 1\n",
      "total ms/img p50: 0.115927 | p95: 0.117655\n",
      "model ms/img p50: 0.114861 | p95: 0.116727\n",
      "overhd ms/img p50: 0.000894 | p95: 0.001538\n",
      "ms/forward (model) p50: 0.114861 | p95: 0.116727\n",
      "throughput img/s p50: 8626.12 | p95: 8673.31\n",
      "peak alloc MB p50: 299.7 | peak reserved MB p50: 508.0\n"
     ]
    }
   ],
   "source": [
    "# Génération\n",
    "model.eval()\n",
    "num_samples = 16\n",
    "noise = torch.randn(num_samples, Z_DIM, 1, 1).to(device)\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# ---------------------------\n",
    "# Utilities\n",
    "# ---------------------------\n",
    "def _sync_if_cuda(device):\n",
    "    if torch.cuda.is_available() and (\"cuda\" in str(device)):\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "def _percentiles(xs, ps=(50, 95)):\n",
    "    xs = np.asarray(xs, dtype=np.float64)\n",
    "    return {f\"p{p}\": float(np.percentile(xs, p)) for p in ps}\n",
    "\n",
    "def sample_z(batch_size: int, z_dim: int, device: str, conv_style: bool = True):\n",
    "    \"\"\"\n",
    "    conv_style=True  -> z is [B, Z, 1, 1] (ConvTranspose2d generators)\n",
    "    conv_style=False -> z is [B, Z]       (MLP / linear-first generators)\n",
    "    \"\"\"\n",
    "    if conv_style:\n",
    "        return torch.randn(batch_size, z_dim, 1, 1, device=device)\n",
    "    return torch.randn(batch_size, z_dim, device=device)\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# ---------------------------\n",
    "# Utilities\n",
    "# ---------------------------\n",
    "def _sync_if_cuda(device):\n",
    "    if torch.cuda.is_available() and (\"cuda\" in str(device)):\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "def _percentiles(xs, ps=(50, 95)):\n",
    "    xs = np.asarray(xs, dtype=np.float64)\n",
    "    return {f\"p{p}\": float(np.percentile(xs, p)) for p in ps}\n",
    "\n",
    "def sample_z(batch_size: int, z_dim: int, device: str, conv_style: bool = True):\n",
    "    \"\"\"\n",
    "    conv_style=True  -> z is [B, Z, 1, 1] (ConvTranspose2d generators)\n",
    "    conv_style=False -> z is [B, Z]       (Linear/MLP generators)\n",
    "    \"\"\"\n",
    "    if conv_style:\n",
    "        return torch.randn(batch_size, z_dim, 1, 1, device=device)\n",
    "    return torch.randn(batch_size, z_dim, device=device)\n",
    "\n",
    "# ---------------------------\n",
    "# Timed Generator Wrapper\n",
    "# ---------------------------\n",
    "class TimedGenerator(nn.Module):\n",
    "    \"\"\"Times generator forward passes. For GAN generation, NFE/sample is always 1.\"\"\"\n",
    "    def __init__(self, generator: nn.Module, device: str):\n",
    "        super().__init__()\n",
    "        self.G = generator\n",
    "        self.device = device\n",
    "        self.reset_stats()\n",
    "\n",
    "    def reset_stats(self):\n",
    "        self.nfe = 0\n",
    "        self.model_ms = 0.0\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, z):\n",
    "        self.nfe += 1\n",
    "        if torch.cuda.is_available() and (\"cuda\" in str(self.device)):\n",
    "            start = torch.cuda.Event(enable_timing=True)\n",
    "            end = torch.cuda.Event(enable_timing=True)\n",
    "            start.record()\n",
    "            out = self.G(z)\n",
    "            end.record()\n",
    "            torch.cuda.synchronize()\n",
    "            self.model_ms += start.elapsed_time(end)\n",
    "            return out\n",
    "        else:\n",
    "            t0 = time.perf_counter()\n",
    "            out = self.G(z)\n",
    "            t1 = time.perf_counter()\n",
    "            self.model_ms += (t1 - t0) * 1000.0\n",
    "            return out\n",
    "\n",
    "# ---------------------------\n",
    "# Benchmark runner\n",
    "# ---------------------------\n",
    "@torch.no_grad()\n",
    "def run_gan_benchmark(\n",
    "    generator: nn.Module,\n",
    "    *,\n",
    "    z_dim: int,\n",
    "    batch_size: int,\n",
    "    device: str,\n",
    "    conv_style_z: bool = True,\n",
    "    warmup_runs: int = 10,\n",
    "    timed_runs: int = 10,\n",
    "    reset_cuda_peak_mem: bool = True,\n",
    "):\n",
    "    generator.eval().to(device)\n",
    "    timed_G = TimedGenerator(generator, device=device).to(device)\n",
    "\n",
    "    # Warmup\n",
    "    for _ in range(warmup_runs):\n",
    "        timed_G.reset_stats()\n",
    "        z = sample_z(batch_size, z_dim, device, conv_style=conv_style_z)\n",
    "        _sync_if_cuda(device)\n",
    "        _ = timed_G(z)\n",
    "        _sync_if_cuda(device)\n",
    "\n",
    "    per_img_total_ms = []\n",
    "    per_img_model_ms = []\n",
    "    per_img_overhd_ms = []\n",
    "    ms_per_forward_model = []\n",
    "    throughput_img_s = []\n",
    "    peak_alloc_mb = []\n",
    "    peak_reserved_mb = []\n",
    "\n",
    "    for _ in range(timed_runs):\n",
    "        timed_G.reset_stats()\n",
    "\n",
    "        if reset_cuda_peak_mem and torch.cuda.is_available() and (\"cuda\" in str(device)):\n",
    "            torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "        z = sample_z(batch_size, z_dim, device, conv_style=conv_style_z)\n",
    "\n",
    "        _sync_if_cuda(device)\n",
    "        t0 = time.perf_counter()\n",
    "        _ = timed_G(z)\n",
    "        _sync_if_cuda(device)\n",
    "        t1 = time.perf_counter()\n",
    "\n",
    "        total_ms_batch = (t1 - t0) * 1000.0\n",
    "        model_ms_batch = float(timed_G.model_ms)\n",
    "        overhd_ms_batch = total_ms_batch - model_ms_batch\n",
    "\n",
    "        total_ms_img = total_ms_batch / batch_size\n",
    "        model_ms_img = model_ms_batch / batch_size\n",
    "        overhd_ms_img = overhd_ms_batch / batch_size\n",
    "\n",
    "        per_img_total_ms.append(total_ms_img)\n",
    "        per_img_model_ms.append(model_ms_img)\n",
    "        per_img_overhd_ms.append(overhd_ms_img)\n",
    "\n",
    "        # For GAN, per-image \"ms/forward\" equals model_ms_img (one forward generates one image)\n",
    "        ms_per_forward_model.append(model_ms_img)\n",
    "\n",
    "        throughput_img_s.append(1000.0 / max(total_ms_img, 1e-12))\n",
    "\n",
    "        if torch.cuda.is_available() and (\"cuda\" in str(device)):\n",
    "            peak_alloc_mb.append(torch.cuda.max_memory_allocated() / (1024**2))\n",
    "            peak_reserved_mb.append(torch.cuda.max_memory_reserved() / (1024**2))\n",
    "\n",
    "    summary = {\n",
    "        \"batch_size\": batch_size,\n",
    "        \"timed_runs\": timed_runs,\n",
    "        \"nfe_sample\": 1,\n",
    "        \"total_ms_img\": _percentiles(per_img_total_ms, ps=(50, 95)),\n",
    "        \"model_ms_img\": _percentiles(per_img_model_ms, ps=(50, 95)),\n",
    "        \"overhd_ms_img\": _percentiles(per_img_overhd_ms, ps=(50, 95)),\n",
    "        \"ms_forward_model\": _percentiles(ms_per_forward_model, ps=(50, 95)),\n",
    "        \"throughput\": _percentiles(throughput_img_s, ps=(50, 95)),\n",
    "        \"peak_alloc_mb_p50\": _percentiles(peak_alloc_mb, ps=(50,))[\"p50\"] if peak_alloc_mb else None,\n",
    "        \"peak_reserved_mb_p50\": _percentiles(peak_reserved_mb, ps=(50,))[\"p50\"] if peak_reserved_mb else None,\n",
    "    }\n",
    "    return summary\n",
    "\n",
    "def pretty_print_gan(summary: dict, name: str):\n",
    "    print(f\"\\n=== Benchmark: {name} ===\")\n",
    "    print(f\"batch={summary['batch_size']} | timed_runs={summary['timed_runs']}\")\n",
    "    print(f\"NFE/sample: {summary['nfe_sample']}\")\n",
    "    print(f\"total ms/img p50: {summary['total_ms_img']['p50']:.6f} | p95: {summary['total_ms_img']['p95']:.6f}\")\n",
    "    print(f\"model ms/img p50: {summary['model_ms_img']['p50']:.6f} | p95: {summary['model_ms_img']['p95']:.6f}\")\n",
    "    print(f\"overhd ms/img p50: {summary['overhd_ms_img']['p50']:.6f} | p95: {summary['overhd_ms_img']['p95']:.6f}\")\n",
    "    print(f\"ms/forward (model) p50: {summary['ms_forward_model']['p50']:.6f} | p95: {summary['ms_forward_model']['p95']:.6f}\")\n",
    "    print(f\"throughput img/s p50: {summary['throughput']['p50']:.2f} | p95: {summary['throughput']['p95']:.2f}\")\n",
    "    if summary[\"peak_alloc_mb_p50\"] is not None:\n",
    "        print(f\"peak alloc MB p50: {summary['peak_alloc_mb_p50']:.1f} | peak reserved MB p50: {summary['peak_reserved_mb_p50']:.1f}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Bind to your notebook's variables (confirmed)\n",
    "# ============================================================\n",
    "generator = model     # <- your GeneratorCorrected instance\n",
    "z_dim = Z_DIM         # <- your latent dimension\n",
    "# device is already defined in your notebook\n",
    "\n",
    "# If you get a conv_transpose2d 4D error, keep True.\n",
    "# If you get a Linear matmul shape error, set False.\n",
    "CONV_STYLE_Z = True\n",
    "\n",
    "# ============================================================\n",
    "# Run\n",
    "# ============================================================\n",
    "b16 = run_gan_benchmark(generator, z_dim=z_dim, batch_size=16, device=device, conv_style_z=CONV_STYLE_Z)\n",
    "pretty_print_gan(b16, name=\"WGAN CIFAR | Generator | batch=16\")\n",
    "\n",
    "b128 = run_gan_benchmark(generator, z_dim=z_dim, batch_size=128, device=device, conv_style_z=CONV_STYLE_Z)\n",
    "pretty_print_gan(b128, name=\"WGAN CIFAR | Generator | batch=128\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
