{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f835933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /opt/python/lib/python3.13/site-packages (5.2.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/python/lib/python3.13/site-packages (from gdown) (4.14.3)\n",
      "Requirement already satisfied: filelock in /opt/python/lib/python3.13/site-packages (from gdown) (3.20.1)\n",
      "Requirement already satisfied: requests[socks] in /opt/python/lib/python3.13/site-packages (from gdown) (2.32.5)\n",
      "Requirement already satisfied: tqdm in /opt/python/lib/python3.13/site-packages (from gdown) (4.67.1)\n",
      "Requirement already satisfied: soupsieve>=1.6.1 in /opt/python/lib/python3.13/site-packages (from beautifulsoup4->gdown) (2.8.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /opt/python/lib/python3.13/site-packages (from beautifulsoup4->gdown) (4.15.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/python/lib/python3.13/site-packages (from requests[socks]->gdown) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/python/lib/python3.13/site-packages (from requests[socks]->gdown) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/python/lib/python3.13/site-packages (from requests[socks]->gdown) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/python/lib/python3.13/site-packages (from requests[socks]->gdown) (2025.11.12)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/python/lib/python3.13/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a8d9260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff24290a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    # Matériel\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Hyperparamètres WGAN-GP\n",
    "    LR = 1e-4\n",
    "    BATCH_SIZE = 64\n",
    "    IMAGE_SIZE = 28\n",
    "    CHANNELS = 1\n",
    "    Z_DIM = 100\n",
    "    NUM_EPOCHS = 20\n",
    "    FEATURES_DIM = 64\n",
    "    CRITIC_ITERATIONS = 5\n",
    "    LAMBDA_GP = 10\n",
    "    \n",
    "    # --- GESTION DES CHEMINS ---\n",
    "    # On suppose que le script tourne dans \"model code/GANs/\"\n",
    "    \n",
    "    # Chemin vers: denoising-diffusion-model/dataset\n",
    "    # Torchvision ajoutera automatiquement le sous-dossier /MNIST\n",
    "    DATA_ROOT = os.path.join(\"..\", \"..\", \"dataset\") \n",
    "    \n",
    "    # Chemin vers: denoising-diffusion-model/model code/GANs/samples\n",
    "    IMG_DIR = \"samples\"\n",
    "    \n",
    "    # Nom du fichier checkpoint\n",
    "    CKPT_NAME = \"wgan_mnist_ckpt.pth\"\n",
    "    \n",
    "    # Fréquence de sauvegarde\n",
    "    SAVE_EVERY = 5\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, channels_img, features_d):\n",
    "        super(Critic, self).__init__()\n",
    "        self.critic = nn.Sequential(\n",
    "            # Input: N x 1 x 28 x 28\n",
    "            nn.Conv2d(channels_img, features_d, kernel_size=4, stride=2, padding=1), # -> 14x14\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            # 14x14 -> 7x7\n",
    "            nn.Conv2d(features_d, features_d * 2, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(features_d * 2, affine=True),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            # 7x7 -> 3x3\n",
    "            nn.Conv2d(features_d * 2, features_d * 4, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(features_d * 4, affine=True),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            # 3x3 -> 1x1\n",
    "            nn.Conv2d(features_d * 4, 1, kernel_size=3, stride=1, padding=0),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.critic(x)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim, channels_img, features_g):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            # Input: Z (N x 100 x 1 x 1) -> 7x7\n",
    "            nn.ConvTranspose2d(z_dim, features_g * 4, kernel_size=7, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(features_g * 4),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # 7x7 -> 14x14\n",
    "            nn.ConvTranspose2d(features_g * 4, features_g * 2, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(features_g * 2),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            # 14x14 -> 28x28\n",
    "            nn.ConvTranspose2d(features_g * 2, channels_img, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh(), # Sortie entre [-1, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gen(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eaf7e9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1_85f6DEJ4lEZl0VWx0V5PzSRMd4-l4yK\n",
      "From (redirected): https://drive.google.com/uc?id=1_85f6DEJ4lEZl0VWx0V5PzSRMd4-l4yK&confirm=t&uuid=87e0042d-05f3-4d0c-bbd6-c92fa5070d87\n",
      "To: /home/onyxia/work/denoising-diffusion-model/measurement code/wgan_mnist_ckpt.pth\n",
      "100%|██████████| 29.3M/29.3M [00:00<00:00, 97.4MB/s]\n"
     ]
    }
   ],
   "source": [
    "import gdown\n",
    "import os\n",
    "\n",
    "file_id = \"1_85f6DEJ4lEZl0VWx0V5PzSRMd4-l4yK\"\n",
    "out_path = \"wgan_mnist_ckpt.pth\"\n",
    "\n",
    "if not os.path.exists(out_path):\n",
    "    gdown.download(\n",
    "        f\"https://drive.google.com/uc?id={file_id}\",\n",
    "        out_path,\n",
    "        quiet=False,\n",
    "    )\n",
    "else:\n",
    "    print(\"Already downloaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d67831a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Benchmark: WGAN MNIST | Generator | batch=16 ===\n",
      "batch=16 | timed_runs=10\n",
      "NFE/sample: 1\n",
      "total ms/img p50: 0.110475 | p95: 0.111467\n",
      "model ms/img p50: 0.105405 | p95: 0.106354\n",
      "overhd ms/img p50: 0.005031 | p95: 0.005405\n",
      "ms/forward (model) p50: 0.105405 | p95: 0.106354\n",
      "throughput img/s p50: 9051.82 | p95: 9112.21\n",
      "peak alloc MB p50: 45.2 | peak reserved MB p50: 100.0\n",
      "\n",
      "=== Benchmark: WGAN MNIST | Generator | batch=128 ===\n",
      "batch=128 | timed_runs=10\n",
      "NFE/sample: 1\n",
      "total ms/img p50: 0.086938 | p95: 0.097352\n",
      "model ms/img p50: 0.086240 | p95: 0.096720\n",
      "overhd ms/img p50: 0.000648 | p95: 0.000740\n",
      "ms/forward (model) p50: 0.086240 | p95: 0.096720\n",
      "throughput img/s p50: 11502.50 | p95: 11520.68\n",
      "peak alloc MB p50: 67.5 | peak reserved MB p50: 100.0\n"
     ]
    }
   ],
   "source": [
    "conf = Config()\n",
    "gen = Generator(conf.Z_DIM, conf.CHANNELS, conf.FEATURES_DIM).to(conf.DEVICE)\n",
    "\n",
    "# Charger le checkpoint\n",
    "ckpt = torch.load(\"wgan_mnist_ckpt.pth\", map_location=conf.DEVICE)\n",
    "gen.load_state_dict(ckpt[\"gen_state\"])\n",
    "gen.eval()\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# ---------------------------\n",
    "# Utilities\n",
    "# ---------------------------\n",
    "def _sync_if_cuda(device):\n",
    "    if torch.cuda.is_available() and (\"cuda\" in str(device)):\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "def _percentiles(xs, ps=(50, 95)):\n",
    "    xs = np.asarray(xs, dtype=np.float64)\n",
    "    return {f\"p{p}\": float(np.percentile(xs, p)) for p in ps}\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# ---------------------------\n",
    "# Utilities\n",
    "# ---------------------------\n",
    "def _sync_if_cuda(device):\n",
    "    if torch.cuda.is_available() and (\"cuda\" in str(device)):\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "def _percentiles(xs, ps=(50, 95)):\n",
    "    xs = np.asarray(xs, dtype=np.float64)\n",
    "    return {f\"p{p}\": float(np.percentile(xs, p)) for p in ps}\n",
    "\n",
    "def sample_z(batch_size: int, z_dim: int, device: str, conv_style: bool = True):\n",
    "    \"\"\"\n",
    "    For ConvTranspose2d generators, z should be [B, Z, 1, 1].\n",
    "    For MLP generators, z is typically [B, Z].\n",
    "    Your error indicates conv_style=True is required.\n",
    "    \"\"\"\n",
    "    if conv_style:\n",
    "        return torch.randn(batch_size, z_dim, 1, 1, device=device)\n",
    "    return torch.randn(batch_size, z_dim, device=device)\n",
    "\n",
    "# ---------------------------\n",
    "# Timed Generator Wrapper\n",
    "# ---------------------------\n",
    "class TimedGenerator(nn.Module):\n",
    "    \"\"\"\n",
    "    Wraps a GAN generator to time forward passes.\n",
    "    For a GAN generator, NFE/sample is always 1 by definition.\n",
    "    \"\"\"\n",
    "    def __init__(self, generator: nn.Module, device: str):\n",
    "        super().__init__()\n",
    "        self.G = generator\n",
    "        self.device = device\n",
    "        self.reset_stats()\n",
    "\n",
    "    def reset_stats(self):\n",
    "        self.nfe = 0\n",
    "        self.model_ms = 0.0\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, z):\n",
    "        self.nfe += 1\n",
    "        if torch.cuda.is_available() and (\"cuda\" in str(self.device)):\n",
    "            start = torch.cuda.Event(enable_timing=True)\n",
    "            end = torch.cuda.Event(enable_timing=True)\n",
    "            start.record()\n",
    "            out = self.G(z)\n",
    "            end.record()\n",
    "            torch.cuda.synchronize()\n",
    "            self.model_ms += start.elapsed_time(end)\n",
    "            return out\n",
    "        else:\n",
    "            t0 = time.perf_counter()\n",
    "            out = self.G(z)\n",
    "            t1 = time.perf_counter()\n",
    "            self.model_ms += (t1 - t0) * 1000.0\n",
    "            return out\n",
    "\n",
    "# ---------------------------\n",
    "# Benchmark runner\n",
    "# ---------------------------\n",
    "@torch.no_grad()\n",
    "def run_gan_benchmark(\n",
    "    generator: nn.Module,\n",
    "    *,\n",
    "    z_dim: int,\n",
    "    batch_size: int,\n",
    "    device: str,\n",
    "    conv_style_z: bool = True,\n",
    "    warmup_runs: int = 2,\n",
    "    timed_runs: int = 10,\n",
    "    reset_cuda_peak_mem: bool = True,\n",
    "):\n",
    "    generator.eval().to(device)\n",
    "    timed_G = TimedGenerator(generator, device=device).to(device)\n",
    "\n",
    "    # Warmup\n",
    "    for _ in range(warmup_runs):\n",
    "        timed_G.reset_stats()\n",
    "        z = sample_z(batch_size, z_dim, device, conv_style=conv_style_z)\n",
    "        _sync_if_cuda(device)\n",
    "        _ = timed_G(z)\n",
    "        _sync_if_cuda(device)\n",
    "\n",
    "    per_img_total_ms = []\n",
    "    per_img_model_ms = []\n",
    "    per_img_overhd_ms = []\n",
    "    ms_per_forward_model = []\n",
    "    throughput_img_s = []\n",
    "    peak_alloc_mb = []\n",
    "    peak_reserved_mb = []\n",
    "\n",
    "    for _ in range(timed_runs):\n",
    "        timed_G.reset_stats()\n",
    "\n",
    "        if reset_cuda_peak_mem and torch.cuda.is_available() and (\"cuda\" in str(device)):\n",
    "            torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "        z = sample_z(batch_size, z_dim, device, conv_style=conv_style_z)\n",
    "\n",
    "        _sync_if_cuda(device)\n",
    "        t0 = time.perf_counter()\n",
    "        _ = timed_G(z)\n",
    "        _sync_if_cuda(device)\n",
    "        t1 = time.perf_counter()\n",
    "\n",
    "        total_ms_batch = (t1 - t0) * 1000.0\n",
    "        model_ms_batch = float(timed_G.model_ms)\n",
    "        overhd_ms_batch = total_ms_batch - model_ms_batch\n",
    "\n",
    "        # Per-image\n",
    "        total_ms_img = total_ms_batch / batch_size\n",
    "        model_ms_img = model_ms_batch / batch_size\n",
    "        overhd_ms_img = overhd_ms_batch / batch_size\n",
    "\n",
    "        per_img_total_ms.append(total_ms_img)\n",
    "        per_img_model_ms.append(model_ms_img)\n",
    "        per_img_overhd_ms.append(overhd_ms_img)\n",
    "\n",
    "        # For GAN, one forward produces one batch -> ms/forward per *image* is model_ms_img\n",
    "        ms_per_forward_model.append(model_ms_img)\n",
    "\n",
    "        throughput_img_s.append(1000.0 / max(total_ms_img, 1e-12))\n",
    "\n",
    "        if torch.cuda.is_available() and (\"cuda\" in str(device)):\n",
    "            peak_alloc_mb.append(torch.cuda.max_memory_allocated() / (1024**2))\n",
    "            peak_reserved_mb.append(torch.cuda.max_memory_reserved() / (1024**2))\n",
    "\n",
    "    summary = {\n",
    "        \"batch_size\": batch_size,\n",
    "        \"timed_runs\": timed_runs,\n",
    "        \"nfe_sample\": 1,\n",
    "\n",
    "        \"total_ms_img\": _percentiles(per_img_total_ms, ps=(50, 95)),\n",
    "        \"model_ms_img\": _percentiles(per_img_model_ms, ps=(50, 95)),\n",
    "        \"overhd_ms_img\": _percentiles(per_img_overhd_ms, ps=(50, 95)),\n",
    "        \"ms_forward_model\": _percentiles(ms_per_forward_model, ps=(50, 95)),\n",
    "        \"throughput\": _percentiles(throughput_img_s, ps=(50, 95)),\n",
    "    }\n",
    "\n",
    "    if peak_alloc_mb:\n",
    "        summary[\"peak_alloc_mb_p50\"] = _percentiles(peak_alloc_mb, ps=(50,))[\"p50\"]\n",
    "        summary[\"peak_reserved_mb_p50\"] = _percentiles(peak_reserved_mb, ps=(50,))[\"p50\"]\n",
    "\n",
    "    return summary\n",
    "\n",
    "def pretty_print_gan(summary: dict, name: str):\n",
    "    print(f\"\\n=== Benchmark: {name} ===\")\n",
    "    print(f\"batch={summary['batch_size']} | timed_runs={summary['timed_runs']}\")\n",
    "    print(f\"NFE/sample: {summary['nfe_sample']}\")\n",
    "    print(f\"total ms/img p50: {summary['total_ms_img']['p50']:.6f} | p95: {summary['total_ms_img']['p95']:.6f}\")\n",
    "    print(f\"model ms/img p50: {summary['model_ms_img']['p50']:.6f} | p95: {summary['model_ms_img']['p95']:.6f}\")\n",
    "    print(f\"overhd ms/img p50: {summary['overhd_ms_img']['p50']:.6f} | p95: {summary['overhd_ms_img']['p95']:.6f}\")\n",
    "    print(f\"ms/forward (model) p50: {summary['ms_forward_model']['p50']:.6f} | p95: {summary['ms_forward_model']['p95']:.6f}\")\n",
    "    print(f\"throughput img/s p50: {summary['throughput']['p50']:.2f} | p95: {summary['throughput']['p95']:.2f}\")\n",
    "    if \"peak_alloc_mb_p50\" in summary:\n",
    "        print(f\"peak alloc MB p50: {summary['peak_alloc_mb_p50']:.1f} | peak reserved MB p50: {summary['peak_reserved_mb_p50']:.1f}\")\n",
    "\n",
    "# ---------------------------\n",
    "# Use YOUR notebook globals (no guessing)\n",
    "# ---------------------------\n",
    "# Your notebook defines: conf, gen\n",
    "device = conf.DEVICE\n",
    "z_dim = conf.Z_DIM\n",
    "generator = gen\n",
    "\n",
    "# Your generator uses ConvTranspose2d -> needs z as [B, Z, 1, 1]\n",
    "CONV_STYLE_Z = True\n",
    "\n",
    "b16 = run_gan_benchmark(generator, z_dim=z_dim, batch_size=16, device=device, conv_style_z=CONV_STYLE_Z)\n",
    "pretty_print_gan(b16, name=\"WGAN MNIST | Generator | batch=16\")\n",
    "\n",
    "b128 = run_gan_benchmark(generator, z_dim=z_dim, batch_size=128, device=device, conv_style_z=CONV_STYLE_Z)\n",
    "pretty_print_gan(b128, name=\"WGAN MNIST | Generator | batch=128\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
